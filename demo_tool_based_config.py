#!/usr/bin/env python3
"""
Demo: Tool-Based Configuration with Small LLM

Shows how a 1.7B model can configure .env using tools:
- get_missing_keys() - returns what's missing
- set_value(key, value) - saves a value
- LLM asks questions, Python handles data
"""

import json
import re
from pathlib import Path
from typing import Dict, List


class ToolBasedConfigurator:
    """
    Demonstrates tool-based configuration approach.
    LLM formulates questions, Python tools handle data.
    """

    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.env_path = Path(".env")
        self.current_env = self._parse_env()

    def _parse_env(self) -> Dict[str, str]:
        """Parse current .env file."""
        env = {}
        if self.env_path.exists():
            with open(self.env_path) as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#") and "=" in line:
                        k, v = line.split("=", 1)
                        env[k.strip()] = v.strip()
        return env

    def _load_metadata(self) -> Dict:
        """Load env_variables.json."""
        metadata_path = self.config_dir / "env_variables.json"
        with open(metadata_path) as f:
            return json.load(f)

    def _get_variable_info(self, key: str, metadata: Dict) -> Dict:
        """Find variable metadata."""
        for category_data in metadata.get("categories", {}).values():
            if key in category_data.get("variables", {}):
                return category_data["variables"][key]
        return {}

    # ========================================================================
    # TOOLS - These are called by the LLM
    # ========================================================================

    def tool_get_missing_keys(self, use_case: str = "local_only") -> str:
        """
        Tool: get_missing_keys()
        Returns JSON with missing keys and their info.
        """
        metadata = self._load_metadata()

        # Get variables for this use case
        use_case_info = metadata["use_cases"].get(use_case, {})
        required = use_case_info.get("required_variables", [])
        optional = use_case_info.get("optional_variables", [])

        # Check what's missing
        missing = []
        for var_list, is_required in [(required, True), (optional, False)]:
            for var in var_list:
                # Handle "One of: KEY1, KEY2" format
                if isinstance(var, str) and var.startswith("One of:"):
                    options = [v.strip() for v in var.replace("One of:", "").split(",")]
                    # If ANY option is set, skip all
                    if any(opt in self.current_env for opt in options):
                        continue
                    # Otherwise, add first option as missing
                    var = options[0]

                # Check if missing
                if var not in self.current_env or not self.current_env[var]:
                    info = self._get_variable_info(var, metadata)
                    missing.append({
                        "key": var,
                        "description": info.get("description", ""),
                        "purpose": info.get("purpose", ""),
                        "required": is_required,
                        "type": info.get("type", "string"),
                        "default": info.get("default"),
                        "how_to_get": info.get("how_to_get", ""),
                        "examples": info.get("examples", []),
                    })

        return json.dumps({
            "status": "complete" if not missing else "incomplete",
            "missing": missing,
            "count": len(missing)
        }, indent=2)

    def tool_set_value(self, key: str, value: str) -> str:
        """
        Tool: set_value(key, value)
        Saves value to .env file.
        """
        # Handle skip/empty
        if not value or value.lower() in ("skip", "none", ""):
            return json.dumps({"success": True, "skipped": True})

        # Boolean normalization
        if value.lower() in ("yes", "y", "true", "1"):
            value = "true"
        elif value.lower() in ("no", "n", "false", "0"):
            value = "false"

        # Update in-memory state
        self.current_env[key] = value

        # Write to file
        try:
            self._write_env()
            return json.dumps({"success": True, "key": key, "value": value})
        except Exception as e:
            return json.dumps({"success": False, "error": str(e)})

    def _write_env(self):
        """Write current_env to .env file."""
        with open(self.env_path, "w") as f:
            f.write("# MoJoAssistant Configuration\n")
            f.write("# Generated by Tool-Based Configurator\n\n")
            for key, value in sorted(self.current_env.items()):
                f.write(f"{key}={value}\n")

    # ========================================================================
    # LLM Integration
    # ========================================================================

    def run_with_llm(self, llm, use_case: str = "local_only"):
        """
        Run configuration with LLM making tool calls.

        The LLM's job:
        1. Call get_missing_keys() to see what's needed
        2. For each missing key, ask user a question
        3. Call set_value(key, value) after user answers
        4. Repeat until get_missing_keys() returns "complete"
        """
        print("\nðŸ’¬ AI Configuration Assistant")
        print("-" * 60)
        print(f"  Configuring for: {use_case.replace('_', ' ').title()}\n")

        # Load system prompt
        prompt_path = self.config_dir / "installer_prompts" / "env_configurator_tool_based.md"
        with open(prompt_path) as f:
            system_prompt = f.read()

        # Conversation loop
        conversation = []
        max_turns = 30

        for turn in range(max_turns):
            if turn == 0:
                prompt = "Call get_missing_keys() to start."
            else:
                prompt = "Continue. Check get_missing_keys() for progress."

            # Get LLM response
            response = llm.chat(prompt, system_prompt=system_prompt)

            # Parse tool calls from response text
            # Format: get_missing_keys() or set_value("KEY", "value")

            if "get_missing_keys()" in response.lower():
                result = self.tool_get_missing_keys(use_case)
                parsed = json.loads(result)
                print(f"\n[Tool] get_missing_keys() -> {parsed['count']} missing\n")

                # If complete, done
                if parsed["status"] == "complete":
                    print("âœ“ Configuration complete!\n")
                    break

                # Add to conversation
                conversation.append(f"Tool result: {result}")
                continue

            # Check for set_value call
            set_match = re.search(r'set_value\(["\']([^"\']+)["\'],\s*["\']([^"\']*)["\']', response)
            if set_match:
                key, value = set_match.groups()
                result = self.tool_set_value(key, value)
                parsed = json.loads(result)

                if parsed.get("skipped"):
                    print(f"  Skipped: {key}")
                elif parsed.get("success"):
                    print(f"  Saved: {key} = {value}")

                conversation.append(f"Tool result: {result}")
                continue

            # Otherwise, LLM is asking user a question
            print(f"AI: {response}")
            user_input = input("You: ").strip()
            conversation.append(f"User: {user_input}")

        print("\nâœ“ Done!")


def demo_without_llm():
    """Demo showing the tools work without LLM."""
    print("=" * 60)
    print("Demo: Tool-Based Configuration (Without LLM)")
    print("=" * 60)

    config = ToolBasedConfigurator()

    # Show what's missing
    print("\n1. Calling get_missing_keys():")
    result = config.tool_get_missing_keys("local_only")
    parsed = json.loads(result)
    print(f"   Status: {parsed['status']}")
    print(f"   Missing: {parsed['count']} keys")

    if parsed["missing"]:
        first = parsed["missing"][0]
        print(f"\n   First missing key: {first['key']}")
        print(f"   Description: {first['description']}")
        print(f"   Required: {first['required']}")

        # Set a value
        print(f"\n2. Calling set_value('{first['key']}', 'true'):")
        result = config.tool_set_value(first["key"], "true")
        print(f"   Result: {result}")

        # Check again
        print("\n3. Calling get_missing_keys() again:")
        result = config.tool_get_missing_keys("local_only")
        parsed = json.loads(result)
        print(f"   Status: {parsed['status']}")
        print(f"   Missing: {parsed['count']} keys")


if __name__ == "__main__":
    demo_without_llm()

    print("\n" + "=" * 60)
    print("To run with LLM:")
    print("=" * 60)
    print("""
from app.installer.bootstrap_llm import BootstrapLLM

llm = BootstrapLLM()
llm.start(quiet=False)

config = ToolBasedConfigurator()
config.run_with_llm(llm, use_case="local_only")
    """)
