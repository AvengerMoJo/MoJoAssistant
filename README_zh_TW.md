# MoJoAssistant - æ‚¨çš„å€‹äºº AI è¨˜æ†¶åŠ©æ‰‹

MoJoAssistant æ˜¯æ‚¨çš„æ™ºèƒ½è¨˜æ†¶å¤¥ä¼´ï¼Œå®ƒå¾æ‚¨çš„å°è©±ä¸­å­¸ç¿’ï¼Œå¹«åŠ©æ‚¨è¨˜ä½ã€æœå°‹ä¸¦éš¨æ™‚é–“å»ºç«‹æ‚¨çš„çŸ¥è­˜ã€‚å®ƒç¶­è­·ä¸€å€‹ç§äººã€æŒä¹…çš„è¨˜æ†¶ç³»çµ±ï¼ŒåŒæ™‚ä½œç‚ºæ©‹æ¨‘ä¾†å¢å¼·æ‚¨èˆ‡ AI åŠ©æ‰‹çš„äº’å‹•ã€‚

## ä»€éº¼æ˜¯ MoJoAssistantï¼Ÿ

MoJoAssistant å¹«åŠ©æ‚¨ï¼š
- **è¨˜ä½ä¸€åˆ‡**ï¼šè·¨æœƒè©±è¿½è¹¤å°è©±ã€å°ˆæ¡ˆå’Œæƒ³æ³•
- **è‡ªç„¶æœå°‹**ï¼šä½¿ç”¨è‡ªç„¶èªè¨€å°‹æ‰¾éå»çš„å°è©±å’Œæ–‡ä»¶
- **å¢å¼· AI äº’å‹•**ï¼šç‚º AI åŠ©æ‰‹æä¾›å€‹äººèƒŒæ™¯ä»¥ç²å¾—æ›´å¥½çš„å›æ‡‰
- **å»ºç«‹çŸ¥è­˜**ï¼šæ·»åŠ æ–‡ä»¶ä¸¦å‰µå»ºå€‹äººçŸ¥è­˜åº«
- **ä¿æŒçµ„ç¹”**ï¼šåœ¨ä¸åŒå°ˆæ¡ˆå’Œèˆˆè¶£é ˜åŸŸé–“ç¶­è­·èƒŒæ™¯

é©åˆå­¸ç”Ÿã€ç ”ç©¶äººå“¡ã€é–‹ç™¼è€…ã€å°ˆæ¥­äººå£«ï¼Œæˆ–ä»»ä½•æƒ³è¦è¨˜ä½æ›´å¤šä¸¦èˆ‡ AI æ›´è°æ˜åœ°å·¥ä½œçš„äººã€‚

## é¡˜æ™¯

MoJoAssistant ä½œç‚ºæ‚¨çš„å€‹äºº AI ä¸­ä»‹ - å®ƒåœ¨ç§äººè¨˜æ†¶ç³»çµ±ä¸­å­¸ç¿’æ‚¨çš„åå¥½ã€èƒŒæ™¯å’Œå°è©±æ­·å²ï¼Œç„¶å¾Œä½¿ç”¨é€™ç¨®ç†è§£ä¾†æ›´æœ‰æ•ˆå’Œå€‹äººåŒ–åœ°èˆ‡å…¬å…± AI ä»£ç†äº’å‹•ã€‚æ‚¨çš„æ•¸æ“šä¿æŒç§å¯†ï¼ŒåŒæ™‚æ‚¨å—ç›Šæ–¼å¢å¼·çš„ã€å€‹äººåŒ–çš„ AI äº’å‹•ã€‚

## æ ¸å¿ƒæ¶æ§‹

MoJoAssistant ç”±å¹¾å€‹æ•´åˆçµ„ä»¶çµ„æˆï¼š

### 1. å€‹äººè¨˜æ†¶ç³»çµ±
- **å·¥ä½œè¨˜æ†¶**ï¼šç•¶å‰å°è©±èƒŒæ™¯å’Œå³æ™‚èƒŒæ™¯
- **æ´»èºè¨˜æ†¶**ï¼šå…·æœ‰èªç¾©æœå°‹åŠŸèƒ½çš„æœ€è¿‘å°è©±  
- **æª”æ¡ˆè¨˜æ†¶**ï¼šåŸºæ–¼å‘é‡æª¢ç´¢çš„é•·æœŸå­˜å„²
- **çŸ¥è­˜ç®¡ç†å™¨**ï¼šå€‹äººæ–‡ä»¶å­˜å„²å’Œèªç¾©æœå°‹

### 2. è¨˜æ†¶è¨ˆç®—å”è­° (MCP) ä¼ºæœå™¨
- **HTTP API**ï¼šè¨˜æ†¶æ“ä½œçš„ RESTful ç«¯é»
- **MCP å”è­°**ï¼šClaude Desktop å’Œå…¶ä»– AI å®¢æˆ¶ç«¯çš„åŸç”Ÿ MCP æ•´åˆ
- **å³æ™‚æ›´æ–°**ï¼šå³æ™‚è¨˜æ†¶ç‹€æ…‹åŒæ­¥
- **å¤šæ¨¡å‹æ”¯æ´**ï¼šå„ç¨®åµŒå…¥å’Œ LLM å¾Œç«¯

### 3. LLM ä»‹é¢å±¤
- **æœ¬åœ° LLM æ”¯æ´**ï¼šç‚ºéš±ç§åœ¨æœ¬åœ°é‹è¡Œæ¨¡å‹
- **API æ•´åˆ**ï¼šé€£æ¥åˆ° OpenAIã€Claude å’Œå…¶ä»–å…¬å…± AI æœå‹™
- **æ··åˆæ¨¡å¼**ï¼šçµåˆæœ¬åœ°å’Œé›²ç«¯æ™ºèƒ½
- **æ¨¡å‹åˆ‡æ›**ï¼šåŸºæ–¼éœ€æ±‚çš„é‹è¡Œæ™‚æ¨¡å‹é¸æ“‡

### 4. ç¶²è·¯æ•´åˆ
- **ç¶²è·¯æœå°‹**ï¼šGoogle è‡ªå®šç¾©æœå°‹ API èˆ‡ DuckDuckGo å‚™ç”¨
- **æ–‡ä»¶è™•ç†**ï¼šå°‡æ–‡ä»¶æ·»åŠ åˆ°æ‚¨çš„çŸ¥è­˜åº«
- **å°è©±è¨˜éŒ„**ï¼šæŒä¹…å°è©±æ­·å²

## ä¸»è¦åŠŸèƒ½

### ğŸ”’ éš±ç§å„ªå…ˆè¨­è¨ˆ
- é è¨­æƒ…æ³ä¸‹æ‰€æœ‰è¨˜æ†¶è™•ç†éƒ½åœ¨æœ¬åœ°é€²è¡Œ
- å€‹äººæ•¸æ“šé™¤éæ˜ç¢ºç™¼é€å¦å‰‡ä¸æœƒé›¢é–‹æ‚¨çš„ç’°å¢ƒ
- ä¸åŒé¡å‹ä¿¡æ¯çš„å¯é…ç½®éš±ç§ç´šåˆ¥
- è¨˜æ†¶åŠ å¯†å’Œå®‰å…¨å­˜å„²é¸é …

### ğŸ§  æŒä¹…å€‹äººè¨˜æ†¶
- **èƒŒæ™¯ç†è§£**ï¼šè¨˜ä½æ‚¨çš„åå¥½ã€é¢¨æ ¼å’ŒèƒŒæ™¯
- **èªç¾©æœå°‹**ï¼šè‡ªç„¶åœ°å°‹æ‰¾éå»çš„å°è©±å’Œä¿¡æ¯
- **çŸ¥è­˜æ•´åˆ**ï¼šé€£æ¥æ‚¨çš„æ–‡ä»¶å’Œè¨˜æ†¶
- **å°è©±é€£çºŒæ€§**ï¼šè·¨æœƒè©±ç¶­è­·èƒŒæ™¯

### ğŸŒ AI ä»£ç†æ©‹æ¨‘
- **ä»£ç†ä»‹é¢**ï¼šä»£è¡¨æ‚¨èˆ‡å…¬å…± AI ä»£ç†é€šä¿¡
- **å€‹äººåŒ–èƒŒæ™¯**ï¼šç‚ºå¤–éƒ¨ AI æä¾›ç›¸é—œçš„å€‹äººèƒŒæ™¯
- **å›æ‡‰å¢å¼·**ï¼šä½¿ç”¨æ‚¨çš„è¨˜æ†¶ä¾†æ”¹å–„ AI å›æ‡‰
- **å¤šä»£ç†æ”¯æ´**ï¼šåŒæ™‚èˆ‡å„ç¨® AI æœå‹™ä»‹é¢

### ğŸ”§ éˆæ´»é…ç½®
- **å¤šå€‹å¾Œç«¯**ï¼šHuggingFaceã€æœ¬åœ°ä¼ºæœå™¨ã€API å’Œå‚™ç”¨é¸é …
- **ç¡¬é«”å„ªåŒ–**ï¼šCPU/GPU æ”¯æ´èˆ‡è‡ªå‹•æª¢æ¸¬
- **æ¨¡å‹åˆ‡æ›**ï¼šç„¡éœ€é‡å•Ÿçš„é‹è¡Œæ™‚æ¨¡å‹æ›´æ”¹
- **å¯è‡ªå®šç¾©æ¶æ§‹**ï¼šæ˜“æ–¼æ“´å±•çš„æ¨¡çµ„åŒ–è¨­è¨ˆ

## 5 åˆ†é˜è©¦ç”¨ MoJoAssistant

### ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆç„¡éœ€è¨­ç½®ï¼‰

**ç„¡éœ€è¨­ç½®ï¼** ç«‹å³é–‹å§‹ä½¿ç”¨æˆ‘å€‘çš„äº’å‹•æ¼”ç¤ºï¼š

```bash
# å…‹éš†å­˜å„²åº«
git clone https://github.com/AvengerMoJo/MoJoAssistant.git
cd MoJoAssistant

# å®‰è£ä¾è³´
pip install -r requirements.txt

# å•Ÿå‹•äº’å‹•æ¼”ç¤ºï¼ˆç«‹å³å¯ç”¨ - ç„¡éœ€è¨­ï¿½ï¿½ï¿½ï¼ï¼‰
python app/interactive-cli.py
```

**åœ¨ CLI ä¸­å˜—è©¦é€™äº›å‘½ä»¤ï¼š**
```
> Hello, what can you help me with?
> /stats
> /help
> I'm working on a Python machine learning project
> What should I focus on next?
```

### ğŸ¯ é¸æ“‡æ‚¨çš„é«”é©—

| ä½¿ç”¨æ¡ˆä¾‹ | æ¨è–¦è¨­ç½® | æ‰€éœ€æ™‚é–“ |
|----------|------------------|---------------|
| **å¿«é€Ÿæ¼”ç¤º** | äº’å‹• CLI | 2 åˆ†é˜ |
| **Claude Desktop** | MCP ä¼ºæœå™¨ | 10 åˆ†é˜ |
| **ç¶²è·¯æ•´åˆ** | HTTP API | 15 åˆ†é˜ |
| **è‡ªå®šç¾©é–‹ç™¼** | Web API | 20 åˆ†é˜ |

### å®Œæ•´å®‰è£

ç”¨æ–¼ç”Ÿç”¢ä½¿ç”¨æˆ–é«˜ç´šåŠŸèƒ½ï¼š

```bash
# 1. å…‹éš†å­˜å„²åº«
git clone https://github.com/AvengerMoJo/MoJoAssistant.git
cd MoJoAssistant

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. è¨­ç½®ç’°å¢ƒï¼ˆé«˜ç´šåŠŸèƒ½å¯é¸ï¼‰
cp .env.example .env
# å¦‚æœä½¿ç”¨é›²æœå‹™ï¼Œè«‹ç·¨è¼¯ .env ä¸¦æ·»åŠ æ‚¨çš„ API é‡‘é‘°
```

## æ‚¨å¯ä»¥ç”¨ MoJoAssistant åšä»€éº¼

### ğŸ“ **å€‹äººçŸ¥è­˜åº«**
æ·»åŠ æ‚¨çš„æ–‡ä»¶ä¸¦é€²è¡Œå°è©±å¼æœå°‹ï¼š
```
> /add README.md
> What does my README say about installation?
> Find all documents related to machine learning
```

### ğŸ’¼ **å·¥ä½œåŠ©æ‰‹**
åœ¨å·¥ä½œæœƒè©±é–“ç¶­è­·èƒŒæ™¯ï¼š
```
> We're designing a new API for our mobile app
> What were we discussing about the API design?
> Remind me of the decisions we made last week
```

### ğŸ“ **å­¸ç¿’å¤¥ä¼´**
è¿½è¹¤æ‚¨çš„å­¸ç¿’é€²åº¦ï¼š
```
> I'm studying Python data structures
> What concepts have I been studying recently?
> Help me understand this based on what I already know
```

### ğŸ¤– **å¢å¼· AI åŠ©æ‰‹**
é€šéæä¾›å€‹äººèƒŒæ™¯å¾ AI ç²å¾—æ›´å¥½çš„å›æ‡‰ï¼š
```
> What should I focus on for my career growth?
> [MoJoAssistant æä¾›é—œæ–¼æ‚¨ç›®æ¨™å’Œèˆˆè¶£çš„å€‹äººèƒŒæ™¯]
> AI å›æ‡‰é€šéæ‚¨çš„å€‹äººä¿¡æ¯å¾—åˆ°å¢å¼·
```

### åŸºæœ¬ä½¿ç”¨

```python
from app.services.memory_service import MemoryService

# åˆå§‹åŒ–æ‚¨çš„å€‹äººè¨˜æ†¶ç³»çµ±
memory_service = MemoryService(data_dir=".my_memory")

# æ·»åŠ å°è©±
memory_service.add_user_message("Hello, I'm working on a project about AI ethics")
memory_service.add_assistant_message("That's interesting! What specific aspects are you exploring?")

# ç‚ºæœªä¾†å°è©±ç²å–èƒŒæ™¯
context = memory_service.get_context_for_query("What was I working on?")
print(context)
```

## å•Ÿå‹• MoJoAssistant

### ğŸš€ **é¸é … 1ï¼šäº’å‹• CLIï¼ˆé¦–æ¬¡æ¨è–¦ï¼‰**
é©åˆç«‹å³è©¦ç”¨ MoJoAssistantï¼š
```bash
python app/interactive-cli.py
```
- ç„¡éœ€é…ç½®
- ç«‹å³è©¦ç”¨æ‰€æœ‰åŠŸèƒ½
- å®Œç¾ç†è§£ MoJoAssistant çš„åŠŸèƒ½

### ğŸ”§ **é¸é … 2ï¼šMCP ä¼ºæœå™¨ï¼ˆç”¨æ–¼ Claude Desktop æ•´åˆï¼‰**
ç”¨æ–¼èˆ‡ Claude Desktop æ•´åˆï¼š
```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨çµ±ä¸€ä¼ºæœå™¨å•Ÿå‹•
python start_mcp_service.py

# æ–¹æ³• 2ï¼šç›´æ¥é‹è¡Œ
python unified_mcp_server.py --mode stdio

# æ–¹æ³• 3ï¼šä½¿ç”¨ç‰¹å®šé…ç½®é‹è¡Œ  
python unified_mcp_server.py --mode stdio --port 8000
```

### ğŸŒ **é¸é … 3ï¼šWeb APIï¼ˆç”¨æ–¼é–‹ç™¼è€…ï¼‰**
ç”¨æ–¼ HTTP API è¨ªå•å’Œè‡ªå®šç¾©æ‡‰ç”¨ç¨‹åºï¼š
```bash
# å•Ÿå‹• HTTP ä¼ºæœå™¨
python unified_mcp_server.py --mode http --port 8000

# æ¸¬è©¦ä¼ºæœå™¨
curl http://localhost:8000/system/health
```

MCP ä¼ºæœå™¨æä¾› HTTP API å’ŒåŸç”Ÿ MCP å”è­°æ”¯æ´ï¼Œå¯èˆ‡ Claude Desktop å’Œå…¶ä»– AI å®¢æˆ¶ç«¯ç„¡ç¸«æ•´åˆã€‚

## è¨˜æ†¶ç³»çµ±æ¶æ§‹

MoJoAssistant å¯¦ç¾äº†è¤‡é›œçš„å¤šå±¤è¨˜æ†¶ç³»çµ±ï¼š

### è¨˜æ†¶å±¤ç´š

1. **å·¥ä½œè¨˜æ†¶** (`app/memory/working_memory.py`)
   - ç•¶å‰å°è©±èƒŒæ™¯
   - çŸ­æœŸæ³¨æ„åŠ›å’Œç„¦é»
   - å³æ™‚å°è©±ç‹€æ…‹

2. **æ´»èºè¨˜æ†¶** (`app/memory/active_memory.py`)
   - æœ€è¿‘å°è©±ï¼ˆæœ€å¾Œ 50-100 æ¢æ¶ˆæ¯ï¼‰
   - æœ€è¿‘äº’å‹•çš„èªç¾©æœå°‹
   - èƒŒæ™¯ç›¸é—œæ€§è©•åˆ†

3. **æª”æ¡ˆè¨˜æ†¶** (`app/memory/archival_memory.py`)
   - é‡è¦è¨˜æ†¶çš„é•·æœŸå­˜å„²
   - åŸºæ–¼å‘é‡çš„èªç¾©æœå°‹
   - è·¨æœƒè©±çš„æŒä¹…è¨˜æ†¶

4. **çŸ¥è­˜ç®¡ç†å™¨** (`app/memory/knowledge_manager.py`)
   - å€‹äººæ–‡ä»¶å­˜å„²
   - æ–‡ä»¶åˆ†å¡Šå’ŒåµŒå…¥
   - çŸ¥è­˜æª¢ç´¢å’Œæ•´åˆ

### åµŒå…¥ç³»çµ±

è¨˜æ†¶ç³»çµ±ä½¿ç”¨é«˜å“è³ªé›™å‘è®Šæ›å™¨æ¨¡å‹é€²è¡Œèªç¾©ç†è§£ï¼š

- **é è¨­æ¨¡å‹**ï¼š`nomic-ai/nomic-embed-text-v2-moe`ï¼ˆ768 ç¶­åº¦ï¼‰
- **æ›¿ä»£æ¨¡å‹**ï¼šBAAI/bge-small-en-v1.5ã€text-embedding-3-small ç­‰
- **å¤šå€‹å¾Œç«¯**ï¼šHuggingFaceã€æœ¬åœ°ä¼ºæœå™¨ã€API å’Œå‚™ç”¨éš¨æ©ŸåµŒå…¥
- **é«˜æ•ˆå¿«å–**ï¼šè‡ªå‹•å¿«å–ä»¥æé«˜æ€§èƒ½
- **ç¡¬é«”å„ªåŒ–**ï¼šCPU/GPU æ”¯æ´èˆ‡è‡ªå‹•æª¢æ¸¬

## AI ä»£ç†æ•´åˆ

MoJoAssistant ä½œç‚ºæ‚¨èˆ‡å…¬å…± AI ä»£ç†äº’å‹•çš„å€‹äººä»£ç†ï¼š

### æ”¯æ´çš„ AI æœå‹™

- **OpenAI GPT æ¨¡å‹**ï¼šChatGPTã€GPT-4ã€GPT-3.5
- **Anthropic Claude**ï¼šClaude 3ã€Claude 2.1
- **Google Gemini**ï¼šGemini Proã€Gemini Ultra
- **æœ¬åœ° LLM**ï¼šOllamaã€æœ¬åœ° HuggingFace æ¨¡å‹
- **API æœå‹™**ï¼šCohereã€å…¶ä»–ç›¸å®¹çš„ AI æœå‹™

### ä»£ç†åŠŸèƒ½

```python
# ç¯„ä¾‹ï¼šMoJoAssistant ä½œç‚º AI ä»£ç†
from app.llm.api_llm_interface import APILLMInterface

# é…ç½®æ‚¨çš„ AI ä»£ç†åå¥½
llm = APILLMInterface(
    model="gpt-4",  # æˆ– "claude-3"ã€"gemini-pro" ç­‰
    api_key="your-api-key",
    base_url="https://api.openai.com/v1"
)

# MoJoAssistant ç‚º AI æä¾›å€‹äººèƒŒæ™¯
response = llm.generate_response(
    user_message="What should I work on today?",
    context=memory_service.get_context_for_query("current projects")
)
```

### éš±ç§é©…å‹•çš„ AI äº’å‹•

- **æœ¬åœ°è™•ç†**ï¼šè¨˜æ†¶æ“ä½œåœ¨ç™¼é€åˆ° AI ä¹‹å‰åœ¨æœ¬åœ°é€²è¡Œ
- **èƒŒæ™¯éæ¿¾**ï¼šåªæœ‰ç›¸é—œçš„å€‹äººèƒŒæ™¯èˆ‡å¤–éƒ¨ AI å…±äº«
- **å›æ‡‰å¢å¼·**ï¼šAI å›æ‡‰é€šéæ‚¨çš„å€‹äººçŸ¥è­˜å¾—åˆ°æ”¹å–„
- **åŒæ„æ§åˆ¶**ï¼šé¸æ“‡èˆ‡å¤–éƒ¨æœå‹™å…±äº«å“ªäº›æ•¸æ“š
## MCP ä¼ºæœå™¨æ•´åˆ

è¨˜æ†¶è¨ˆç®—å”è­° (MCP) ä¼ºæœå™¨å¯¦ç¾èˆ‡ AI å®¢æˆ¶ç«¯çš„ç„¡ç¸«æ•´åˆï¼š

### å•Ÿå‹•ä¼ºæœå™¨

```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨çµ±ä¸€ä¼ºæœå™¨å•Ÿå‹•
python start_mcp_service.py

# æ–¹æ³• 2ï¼šç›´æ¥é‹è¡Œ
python unified_mcp_server.py

# æ–¹æ³• 3ï¼šä½¿ç”¨ç‰¹å®šé…ç½®é‹è¡Œ  
python unified_mcp_server.py --mode stdio
```

### å¯ç”¨ç«¯é»

MCP ä¼ºæœå™¨æä¾› HTTP API å’ŒåŸç”Ÿ MCP å”è­°æ”¯æ´ï¼š

#### è¨˜æ†¶æ“ä½œ
- `POST /memory/conversation` - æ·»åŠ å°è©±æ¶ˆæ¯
- `GET /memory/conversation` - ç²å–ç•¶å‰å°è©±
- `POST /memory/knowledge` - å°‡æ–‡ä»¶æ·»åŠ åˆ°çŸ¥è­˜åº«
- `GET /memory/knowledge` - åˆ—å‡ºçŸ¥è­˜æ–‡ä»¶
- `GET /memory/context` - ç²å–æŸ¥è©¢çš„è¨˜æ†¶èƒŒæ™¯

#### ç³»çµ±æ“ä½œ
- `GET /system/health` - å¥åº·æª¢æŸ¥
- `GET /system/info` - æœå‹™ä¿¡æ¯
- `POST /embeddings/switch` - åˆ‡æ›åµŒå…¥æ¨¡å‹

#### é…ç½®
- `GET /config/embeddings` - åˆ—å‡ºå¯ç”¨çš„åµŒå…¥æ¨¡å‹
- `POST /embeddings/switch` - åˆ‡æ›åˆ°ä¸åŒçš„åµŒå…¥æ¨¡å‹

### Claude Desktop æ•´åˆ

é…ç½® Claude Desktop ä½¿ç”¨ MoJoAssistant ä½œç‚º MCP ä¼ºæœå™¨ï¼š

1. ç·¨è¼¯æ‚¨çš„ Claude Desktop é…ç½®ï¼š
```json
{
  "mcpServers": {
    "mojo-assistant": {
      "command": "python",
      "args": ["/path/to/MoJoAssistant/unified_mcp_server.py"],
      "env": {}
    }
  }
}
```

2. é‡å•Ÿ Claude Desktop ä»¥è¼‰å…¥ MCP ä¼ºæœå™¨

### Bruno é›†åˆæ•´åˆ

å°ˆæ¡ˆåŒ…å«ç”¨æ–¼ API æ¸¬è©¦çš„ Bruno é›†åˆï¼š
- `bruno_collection/` - åŒ…å«é é…ç½®çš„ API è«‹æ±‚
- ä½¿ç”¨ Bruno æ¸¬è©¦æ‰€æœ‰ç«¯é»æˆ–å°å…¥åˆ° Postman

## é…ç½®

MoJoAssistant ä½¿ç”¨éˆæ´»çš„é…ç½®ç³»çµ±ï¼š

### ç’°å¢ƒè®Šæ•¸

å¾æ¨¡æ¿å‰µå»º `.env` æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

**å¿«é€Ÿé–‹å§‹é…ç½®**ï¼ˆç”¨æ–¼é–‹ç™¼ï¼‰ï¼š
```env
# å¿«é€Ÿé–‹å§‹æ™‚ï¼Œä¿æŒ MCP_REQUIRE_AUTH=false
MCP_REQUIRE_AUTH=false
MCP_API_KEY=demo_key_for_development

# å¯é¸ï¼šGoogle æœå°‹ï¼ˆå¢å¼·ç¶²è·¯æœå°‹ï¼‰
# GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_SEARCH_ENGINE_ID=your_search_engine_id_here

# æ—¥èªŒè¨˜éŒ„
LOG_LEVEL=INFO
```

**é«˜ç´šé…ç½®**ï¼ˆç”¨æ–¼ç”Ÿç”¢ï¼‰ï¼š
```env
# LLM é…ç½®
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
GOOGLE_API_KEY=your-google-key

# æœå°‹é…ç½®  
GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id

# MCP é…ç½®
MCP_REQUIRE_AUTH=true
MCP_API_KEY=your_secure_api_key

# å¯é¸ï¼šæœ¬åœ°æ¨¡å‹è·¯å¾‘
LOCAL_MODEL_PATH=/path/to/local/models
```

### é…ç½®æ–‡ä»¶

#### åµŒå…¥é…ç½® (`config/embedding_config.json`)
```json
{
  "embedding_models": {
    "default": {
      "backend": "huggingface",
      "model_name": "nomic-ai/nomic-embed-text-v2-moe",
      "embedding_dim": 768,
      "device": "auto"
    },
    "fast": {
      "backend": "huggingface", 
      "model_name": "BAAI/bge-small-en-v1.5",
      "embedding_dim": 384,
      "device": "cpu"
    }
  }
}
```

#### LLM é…ç½® (`config/llm_config.json`)
```json
{
  "llm_backends": {
    "openai": {
      "api_key": "${OPENAI_API_KEY}",
      "base_url": "https://api.openai.com/v1",
      "models": ["gpt-4", "gpt-3.5-turbo"]
    },
    "anthropic": {
      "api_key": "${ANTHROPIC_API_KEY}",
      "models": ["claude-3-opus", "claude-3-sonnet"]
    }
  }
}
```

#### MCP é…ç½® (`config/mcp_config.json`)
```json
{
  "server": {
    "host": "localhost",
    "port": 8000,
    "debug": false
  },
  "memory": {
    "data_dir": ".memory",
    "max_conversation_length": 100,
    "archive_threshold": 50
  }
}
```
## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬è¨˜æ†¶æ“ä½œ

```python
from app.services.memory_service import MemoryService

# åˆå§‹åŒ–æ‚¨çš„å€‹äººè¨˜æ†¶ç³»çµ±
memory_service = MemoryService(data_dir=".my_memory")

# é€²è¡Œå°è©±
memory_service.add_user_message("I'm working on a machine learning project")
memory_service.add_assistant_message("That sounds exciting! What type of ML project?")

# ç¨å¾Œï¼Œè©¢å•æ‚¨çš„å°ˆæ¡ˆ
context = memory_service.get_context_for_query("What projects am I working on?")
print(context)
# è¿”å›é—œæ–¼æ‚¨ ML å°ˆæ¡ˆçš„ç›¸é—œèƒŒæ™¯
```

### æ–‡ä»¶çŸ¥è­˜åº«

```python
# å°‡æ–‡ä»¶æ·»åŠ åˆ°æ‚¨çš„çŸ¥è­˜åº«
memory_service.add_to_knowledge_base(
    document="My research paper on neural networks",
    metadata={"type": "research", "project": "ml-project"}
)

# æœå°‹æ‚¨çš„çŸ¥è­˜åº«
results = memory_service.knowledge_manager.query("neural networks")
for doc, score in results:
    print(f"Document: {doc[:100]}... (Score: {score:.2f})")
```

### AI ä»£ç†ä»£ç†ç¯„ä¾‹

```python
from app.llm.api_llm_interface import APILLMInterface
from app.services.memory_service import MemoryService

# è¨­ç½®æ‚¨çš„è¨˜æ†¶ç³»çµ±
memory = MemoryService()

# é…ç½® AI ä»£ç†ä»£ç†
llm = APILLMInterface(
    model="gpt-4",
    api_key="your-api-key",
    base_url="https://api.openai.com/v1"
)

# ç”¨æˆ¶é€šéæ‚¨çš„ä»£ç†æå•
user_question = "What should I focus on for my career growth?"

# å¾æ‚¨çš„è¨˜æ†¶ä¸­ç²å–å€‹äººèƒŒæ™¯
personal_context = memory.get_context_for_query("career goals and interests")

# ä½¿ç”¨å€‹äººèƒŒæ™¯ç”Ÿæˆ AI å›æ‡‰
response = llm.generate_response(
    user_message=user_question,
    context=personal_context
)

print(response)
# AI å›æ‡‰é€šéæ‚¨çš„å€‹äººèƒŒæ™¯å¾—åˆ°å¢å¼·
```

### äº’å‹• CLI ä½¿ç”¨

```bash
# å•Ÿå‹•äº’å‹• CLI
python app/interactive-cli.py

# å¯ç”¨å‘½ä»¤ï¼š
/embed          # é¡¯ç¤ºç•¶å‰åµŒå…¥æ¨¡å‹
/embed fast     # åˆ‡æ›åˆ°å¿«é€ŸåµŒå…¥æ¨¡å‹  
/stats          # é¡¯ç¤ºè¨˜æ†¶çµ±è¨ˆ
/knowledge add  # å°‡æ–‡ä»¶æ·»åŠ åˆ°çŸ¥è­˜åº«
/memory save    # ä¿å­˜è¨˜æ†¶ç‹€æ…‹
/memory load    # è¼‰å…¥è¨˜æ†¶ç‹€æ…‹
/help           # é¡¯ç¤ºæ‰€æœ‰å‘½ä»¤
```

### MCP ä¼ºæœå™¨ API ä½¿ç”¨

```python
import requests

# é€šé HTTP API æ·»åŠ å°è©±
response = requests.post(
    "http://localhost:8000/memory/conversation",
    json={
        "role": "user", 
        "content": "I need help with my coding project"
    }
)

# ç‚º AI ç²å–è¨˜æ†¶èƒŒæ™¯
context_response = requests.get(
    "http://localhost:8000/memory/context",
    params={"query": "coding project"}
)

context = context_response.json()
```

### ç¶²è·¯æœå°‹æ•´åˆ

```python
# å•Ÿç”¨æ™‚ç³»çµ±è‡ªå‹•ä½¿ç”¨ç¶²è·¯æœå°‹
# åœ¨ .env ä¸­è¨­ç½® GOOGLE_API_KEY å’Œ GOOGLE_SEARCH_ENGINE_ID

# æœå°‹çµæœèˆ‡æ‚¨çš„å€‹äººè¨˜æ†¶æ•´åˆ
# ä»¥ç²å¾—æ›´ç›¸é—œå’Œå€‹äººåŒ–çš„å›æ‡‰
```

## å®‰è£èˆ‡è¨­ç½®

### å…ˆæ±ºæ¢ä»¶

- Python 3.8+
- Gitï¼ˆç”¨æ–¼å…‹éš†ï¼‰
- å¯é¸ï¼šæ”¯æ´ CUDA çš„ GPU ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦

### å¿«é€Ÿå®‰è£ï¼ˆ5 åˆ†é˜ï¼‰

```bash
# 1. å…‹éš†å­˜å„²åº«
git clone https://github.com/AvengerMoJo/MoJoAssistant.git
cd MoJoAssistant

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. å•Ÿå‹•äº’å‹•æ¼”ç¤ºï¼ˆç„¡éœ€é…ç½®ï¼ï¼‰
python app/interactive-cli.py
```

### å®Œæ•´å®‰è£ï¼ˆç”¨æ–¼é«˜ç´šåŠŸèƒ½ï¼‰

```bash
# 1. å…‹éš†å­˜å„²åº«
git clone https://github.com/AvengerMoJo/MoJoAssistant.git
cd MoJoAssistant

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. è¨­ç½®ç’°å¢ƒï¼ˆé«˜ç´šåŠŸèƒ½å¯é¸ï¼‰
cp .env.example .env
# å¦‚æœä½¿ç”¨é›²æœå‹™ï¼Œè«‹ç·¨è¼¯ .env ä¸¦æ·»åŠ æ‚¨çš„ API é‡‘é‘°

# 5. ä¸‹è¼‰åµŒå…¥æ¨¡å‹ï¼ˆå¯é¸ï¼Œé¦–æ¬¡ä½¿ç”¨æ™‚æœƒä¸‹è¼‰ï¼‰
# ç³»çµ±æœƒåœ¨é¦–æ¬¡è¨ªå•æ™‚è‡ªå‹•ä¸‹è¼‰æ¨¡å‹
```

### å¯é¸ä¾è³´

ç”¨æ–¼å¢å¼·åŠŸèƒ½ï¼š

```bash
# GPU åŠ é€Ÿ
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å¤§å‹æ¨¡å‹çš„æ›´å¥½æ€§èƒ½
pip install flash-attn --no-build-isolation

# é«˜ç´šç¶²è·¯æœå°‹
pip install google-api-python-client

# ç›£æ§å’ŒæŒ‡æ¨™
pip install psutil  # å¯é¸ç³»çµ±ç›£æ§
```
## æ€§èƒ½èˆ‡å„ªåŒ–

### ç³»çµ±éœ€æ±‚

- **æœ€ä½**ï¼š4GB RAMï¼Œ2 CPU æ ¸å¿ƒ
- **æ¨è–¦**ï¼š8GB+ RAMï¼Œ4+ CPU æ ¸å¿ƒï¼ŒGPU å¯é¸
- **é«˜æ€§èƒ½**ï¼š16GB+ RAMï¼Œ8+ CPU æ ¸å¿ƒï¼Œå°ˆç”¨ GPU

### å„ªåŒ–æŠ€å·§

1. **æ¨¡å‹é¸æ“‡**ï¼š
   - åœ¨è³‡æºå—é™ç’°å¢ƒä¸­ä½¿ç”¨ `BAAI/bge-small-en-v1.5`
   - ä½¿ç”¨ `nomic-ai/nomic-embed-text-v2-moe` ç²å¾—æœ€ä½³å“è³ª
   - åœ¨åƒ… CPU ç’°å¢ƒä¸­è€ƒæ…®é›² API

2. **ç¡¬é«”å„ªåŒ–**ï¼š
   ```python
   # è‡ªå‹•æª¢æ¸¬æœ€ä½³è¨­å‚™
   memory_service = MemoryService(
       embedding_device="auto"  # å¦‚æœå¯ç”¨å°‡ä½¿ç”¨ GPU
   )
   ```

3. **è¨˜æ†¶ç®¡ç†**ï¼š
   - å®šæœŸæ­¸æª”èˆŠå°è©±
   - å¯é…ç½®çš„å°è©±é•·åº¦é™åˆ¶
   - è‡ªå‹•æ¸…ç†è‡¨æ™‚æ–‡ä»¶

4. **å¿«å–**ï¼š
   - åµŒå…¥å¿«å–æ¸›å°‘è¨ˆç®—æ™‚é–“
   - æ¨¡å‹å¿«å–åŠ é€Ÿé‡è¤‡æ“ä½œ
   - è‡ªå‹•å¿«å–ç®¡ç†

## é«˜ç´šåŠŸèƒ½

### å¤šæ¨¡å‹æ¶æ§‹

MoJoAssistant åŒæ™‚æ”¯æ´å¤šå€‹ AI æ¨¡å‹ï¼š

```python
# é…ç½®å¤šå€‹ LLM å¾Œç«¯
from app.llm.hybrid_llm_interface import HybridLLMInterface

hybrid_llm = HybridLLMInterface(
    models={
        "primary": "gpt-4",
        "fallback": "claude-3",
        "local": "local-model"
    }
)
```

### éš±ç§èˆ‡å®‰å…¨

- **æœ¬åœ°è™•ç†**ï¼šé è¨­æƒ…æ³ä¸‹æ‰€æœ‰è¨˜æ†¶æ“ä½œéƒ½åœ¨æœ¬åœ°é€²è¡Œ
- **æ•¸æ“šåŠ å¯†**ï¼šå­˜å„²è¨˜æ†¶çš„å¯é¸åŠ å¯†
- **API é‡‘é‘°å®‰å…¨**ï¼šAPI é‡‘é‘°çš„å®‰å…¨å­˜å„²å’Œç®¡ç†
- **è¨ªå•æ§åˆ¶**ï¼šè¨˜æ†¶æ•¸æ“šçš„å¯é…ç½®è¨ªå•æ§åˆ¶

### ç›£æ§èˆ‡å¯è§€å¯Ÿæ€§

```python
# ç²å–ç³»çµ±çµ±è¨ˆ
stats = memory_service.get_memory_stats()
print(f"Total memories: {stats['total_memories']}")
print(f"Knowledge documents: {stats['knowledge_documents']}")
print(f"Embedding model: {stats['embedding_model']}")

# ç›£æ§ç³»çµ±å¥åº·
health = mcp_service.get_system_health()
print(f"System status: {health['status']}")
print(f"Memory usage: {health['memory_usage']}")
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **æ¨¡å‹ä¸‹è¼‰å¤±æ•—**ï¼š
   ```bash
   # æª¢æŸ¥ç¶²è·¯é€£æ¥ä¸¦é‡è©¦
   python -c "from app.memory.simplified_embeddings import SimpleEmbedding; SimpleEmbedding()"
   ```

2. **è¨˜æ†¶æœªæŒä¹…åŒ–**ï¼š
   - æª¢æŸ¥æ•¸æ“šç›®éŒ„çš„æ–‡ä»¶æ¬Šé™
   - é©—è­‰ç£ç¢Ÿç©ºé–“å¯ç”¨æ€§
   - æª¢æŸ¥æ­£ç¢ºçš„æ–‡ä»¶è·¯å¾‘é…ç½®

3. **API é€£æ¥å•é¡Œ**ï¼š
   - é©—è­‰ API é‡‘é‘°åœ¨ `.env` ä¸­æ­£ç¢ºè¨­ç½®
   - æª¢æŸ¥åˆ° API ç«¯é»çš„ç¶²è·¯é€£æ¥
   - å–®ç¨æ¸¬è©¦ API é€£æ¥

4. **æ€§èƒ½å•é¡Œ**ï¼š
   - ä½¿ç”¨ `htop` æˆ– `ä»»å‹™ç®¡ç†å™¨` ç›£æ§ç³»çµ±è³‡æº
   - è€ƒæ…®åˆ‡æ›åˆ°è¼ƒå°çš„åµŒå…¥æ¨¡å‹
   - å¦‚æœå¯ç”¨ï¼Œå•Ÿç”¨ GPU åŠ é€Ÿ

### èª¿è©¦æ¨¡å¼

å•Ÿç”¨èª¿è©¦æ—¥èªŒè¨˜éŒ„é€²è¡Œæ•…éšœæ’é™¤ï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# æˆ–åœ¨é…ç½®ä¸­
{
  "debug": true,
  "log_level": "DEBUG"
}
```

## å¸¸è¦‹å•é¡Œæ•…éšœæ’é™¤

### **"æ‰¾ä¸åˆ°æ¨¡çµ„" éŒ¯èª¤**
```bash
# ç¢ºä¿æ‚¨åœ¨å°ˆæ¡ˆç›®éŒ„ä¸­ä¸”è™›æ“¬ç’°å¢ƒå·²æ¿€æ´»
cd MoJoAssistant
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### **ç„¡æ³•å…‹éš†å­˜å„²åº«**
```bash
# å¦‚æœ URL ä¸èµ·ä½œç”¨ï¼Œè«‹å˜—è©¦ï¼š
git clone https://github.com/AvengerMoJo/MoJoAssistant.git
```

### **åµŒå…¥æ¨¡å‹è¼‰å…¥å¤±æ•—**
```bash
# å˜—è©¦å¿«é€Ÿæ¨¡å‹æˆ–å‚™ç”¨
/embed fast
# æˆ–ä½¿ç”¨éš¨æ©ŸåµŒå…¥ä½œç‚ºå‚™ç”¨
/embed fallback
```

### **è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤**
```bash
# ä½¿ç”¨ CPU è€Œä¸æ˜¯ GPU
export EMBEDDING_DEVICE="cpu"
# æˆ–ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
/embed fast
```

### **CLI æ²’æœ‰ç«‹å³æˆåŠŸ**
CLI ç„¡éœ€é…ç½®å³å¯ç«‹å³å·¥ä½œã€‚å¦‚æœæ‚¨é‡åˆ°å•é¡Œï¼š
1. ç¢ºä¿æ‚¨åœ¨æ­£ç¢ºçš„ç›®éŒ„ä¸­
2. æª¢æŸ¥è™›æ“¬ç’°å¢ƒæ˜¯å¦å·²æ¿€æ´»
3. å˜—è©¦é‡æ–°å®‰è£ä¾è³´ï¼š`pip install -r requirements.txt`

### **ç²å¾—å¹«åŠ©**
- åœ¨ CLI ä¸­ä½¿ç”¨ `/help` ç²å–å‘½ä»¤åƒè€ƒ
- ä½¿ç”¨ `/stats` æª¢æŸ¥è¨˜æ†¶ç³»çµ±ç‹€æ…‹
- æª¢æŸ¥ `.memory/` ç›®éŒ„ä¸­çš„æ—¥èªŒä»¥ç²å–è©³ç´°éŒ¯èª¤ä¿¡æ¯
- æŸ¥çœ‹ `docs/` ä¸­çš„æ–‡æª”ä»¥äº†è§£é«˜ç´šç”¨æ³•

## è²¢ç»

MoJoAssistant è¨­è¨ˆç‚ºå¯æ“´å±•ã€‚ä¸»è¦è²¢ç»é ˜åŸŸï¼š

- **æ–°è¨˜æ†¶å±¤ç´š**ï¼šé¡å¤–çš„è¨˜æ†¶å­˜å„²å¾Œç«¯
- **AI ä»£ç†æ•´åˆ**ï¼šæ”¯æ´æ›´å¤š AI æœå‹™
- **åµŒå…¥æ¨¡å‹**ï¼šèˆ‡æ–°åµŒå…¥æŠ€è¡“çš„æ•´åˆ
- **éš±ç§åŠŸèƒ½**ï¼šå¢å¼·çš„å®‰å…¨å’Œéš±ç§æ§åˆ¶
- **æ€§èƒ½å„ªåŒ–**ï¼šé€Ÿåº¦å’Œæ•ˆç‡æ”¹é€²

è©³ç´°çš„è²¢ç»æŒ‡å—è«‹åƒè¦‹ `CONTRIBUTING.md`ã€‚

## æˆæ¬Š

æ­¤å°ˆæ¡ˆæ ¹æ“š MIT æˆæ¬Šæ¢æ¬¾æˆæ¬Š - è©³æƒ…è«‹åƒè¦‹ `LICENSE` æ–‡ä»¶ã€‚

## ä¸‹ä¸€æ­¥

### ğŸ¯ **ç¬¬ä¸€æ¬¡æœƒè©±å¾Œ**
1. **æ·»åŠ æ‚¨çš„æ–‡ä»¶**ï¼šä½¿ç”¨ `/add filename` å°å…¥æ‚¨çš„æ–‡ä»¶
2. **å¯¦é©—æ¨¡å‹**ï¼šå˜—è©¦ `/embed fast` ä»¥ç²å¾—æ›´å¥½çš„æ€§èƒ½
3. **ä¿å­˜é‡è¦å°è©±**ï¼šä½¿ç”¨ `/save my_conversation.json`
4. **æ¢ç´¢è¨˜æ†¶çµ±è¨ˆ**ï¼šä½¿ç”¨ `/stats` æŸ¥çœ‹æ‚¨çš„è¨˜æ†¶ä½¿ç”¨æƒ…æ³

### ğŸš€ **é«˜ç´šè¨­ç½®**
1. **Claude Desktop æ•´åˆ**ï¼šè¨­ç½® MCP ä¼ºæœå™¨ä»¥ç„¡ç¸«è¨ªå• AI åŠ©æ‰‹
2. **ç¶²è·¯æœå°‹**ï¼šé…ç½® Google API ä»¥å¢å¼·æœå°‹åŠŸèƒ½
3. **è‡ªå®šç¾©æ‡‰ç”¨ç¨‹åº**ï¼šä½¿ç”¨ HTTP API é€²è¡Œæ‚¨è‡ªå·±çš„æ•´åˆ
4. **å¤šå€‹æ¨¡å‹**ï¼šåœ¨ä¸åŒçš„åµŒå…¥å’Œ LLM æ¨¡å‹ä¹‹é–“åˆ‡æ›

### ğŸ“š **äº†è§£æ›´å¤š**
- **API æ–‡æª”**ï¼šè©³ç´°æŠ€è¡“æ–‡æª”è«‹åƒè¦‹ `docs/`
- **Google API è¨­ç½®**ï¼šå¢å¼·ç¶²è·¯æœå°‹è«‹éµå¾ª `GOOGLE_API_SETUP.md`
- **Claude æ•´åˆ**ï¼šClaude Desktop è¨­ç½®è«‹æŸ¥çœ‹ `claude-docs/`
- **ç¯„ä¾‹**ï¼šé«˜ç´šç”¨æ³•è«‹æ¢ç´¢ `example.py` å’Œ `experimental/`

### ğŸ¤ **ç¤¾ç¾¤èˆ‡æ”¯æ´**
- **å•é¡Œ**ï¼šåœ¨ GitHub Issues ä¸Šå ±å‘ŠéŒ¯èª¤å’Œè«‹æ±‚åŠŸèƒ½
- **è¨è«–**ï¼šåŠ å…¥ GitHub Discussions ä¸Šçš„è¨è«–  
- **ç¤¾ç¾¤**ï¼šèˆ‡å…¶ä»–ç”¨æˆ¶å’Œè²¢ç»è€…è¯ç¹«
- **è²¢ç»**ï¼šé–‹ç™¼æŒ‡å—è«‹åƒè¦‹ `CONTRIBUTING.md`

---

## MoJoAssistantï¼šæ‚¨çš„ AI è¨˜æ†¶å¤¥ä¼´

MoJoAssistant å¹«åŠ©æ‚¨è¨˜ä½æ›´å¤šã€å·¥ä½œæ›´è°æ˜ï¼Œä¸¦éš¨æ™‚é–“å»ºç«‹æŒä¹…çš„çŸ¥è­˜ã€‚ç„¡è«–æ‚¨æ˜¯å­¸ç”Ÿã€ç ”ç©¶äººå“¡ã€é–‹ç™¼è€…é‚„æ˜¯å°ˆæ¥­äººå£«ï¼Œå®ƒéƒ½èƒ½é©æ‡‰æ‚¨çš„éœ€æ±‚ä¸¦èˆ‡æ‚¨ä¸€èµ·æˆé•·ã€‚

**ä»Šå¤©å°±é–‹å§‹**é«”é©—ç”± AI å¢å¼·çš„æŒä¹…ã€å€‹äººè¨˜æ†¶çš„åŠ›é‡ã€‚

**å¿«é€Ÿæé†’**ï¼šå¦‚æœé‡åˆ°å•é¡Œï¼Œåˆ¥å¿˜äº†ç‚º git æ“ä½œè¨­ç½®æ‚¨çš„ GPG å¯†ç¢¼çŸ­èªï¼
